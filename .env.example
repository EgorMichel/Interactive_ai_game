# .env.example
# Copy this file to .env and fill in your actual API keys.

# ==========================================================
# LLM Settings
# ==========================================================
# Required for LiteLLM to work with OpenAI-compatible APIs (like OpenAI, Llama, etc.)
LLM_API_KEY=your_llm_api_key_here

# Optional: Base URL for your LLM provider.
# LiteLLM often infers this, but specify for custom/local endpoints.
# Example for OpenAI: LLM_API_BASE=https://api.openai.com/v1
# Example for Ollama: LLM_API_BASE=http://localhost:11434
# Example for Azure: LLM_API_BASE=https://YOUR_RESOURCE_NAME.openai.azure.com/openai/deployments/YOUR_DEPLOYMENT_NAME
LLM_API_BASE=

# Optional: The name of the LLM model to use.
# Example: gpt-3.5-turbo, gpt-4, ollama/llama2, claude-3-opus-20240229
LLM_MODEL_NAME=gpt-3.5-turbo

# ==========================================================
# Other settings (optional)
# ==========================================================
# Any other application-wide settings can go here.
# For example:
# DATABASE_URL=sqlite:///game.db
